---
layout: post
title:  "Distributional Successor Features Enable Zero-Shot Policy Optimization"
date:   2024-10-05 22:21:59 +00:00
end_date:   Present
image: /images/x1.png
categories: research
authors: "Chuning Zhu, Xinqi Wang, <strong>Tyler Han</strong>, Simon Du, Abhishek Gupta"
venue: "Neural Information Processing Systems (NeurIPS)"
arxiv: https://arxiv.org/abs/2403.06328
website: https://weirdlabuw.github.io/gom/
code: https://github.com/WEIRDLabUW/gom
---
Intelligent agents must be generalists, capable of quickly adapting to various tasks. In reinforcement learning (RL), model-based RL learns a dynamics model of the world, in principle enabling transfer to arbitrary reward functions through planning. However, autoregressive model rollouts suffer from compounding error, making model-based RL ineffective for long-horizon problems. Successor features offer an alternative by modeling a policy's long-term state occupancy, reducing policy evaluation under new rewards to linear regression. Yet, zero-shot policy optimization for new tasks with successor features can be challenging. This work proposes a novel class of models, i.e., Distributional Successor Features for Zero-Shot Policy Optimization (DiSPOs), that learn a distribution of successor features of a stationary dataset's behavior policy, along with a policy that acts to realize different successor features achievable within the dataset. By directly modeling long-term outcomes in the dataset, DiSPOs avoid compounding error while enabling a simple scheme for zero-shot policy optimization across reward functions. We present a practical instantiation of DiSPOs using diffusion models and show their efficacy as a new class of transferable models, both theoretically and empirically across various simulated robotics problems. Videos and code: https://weirdlabuw.github.io/gom/.